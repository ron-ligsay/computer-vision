{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras ImageDataGenerator\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"/tmp/rps\"\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                        rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                                        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                                        shear_range=0.2,  # set range for random shear\n",
    "                                        zoom_range=0.2,  # set range for random zoom\n",
    "                                        horizontal_flip=True,  # randomly flip images\n",
    "                                        fill_mode='nearest'  # set mode for filling points outside the input boundaries\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = training_datagen.flow_from_directory(TRAINING_DIR, target_size(150,150), class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = training_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                        target_size=(150,150), # all images will be resized to 150x150\n",
    "                                                        class_mode='categorical', # since we use categorical_crossentropy loss, we need categorical labels\n",
    "                                                        batch_size=126 # 126 images per batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                             target_size=(150,150),\n",
    "                                                             class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data\n",
    "history = model.fit(train_generator, epochs=25, validation_data = validator_generator, verbose = 1)\n",
    "# or\n",
    "#history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validator_generator, verbose = 1, validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc)) # Get number of epochs\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.predict(train_generator, batch_size=10) # or batch size 216"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
